\documentclass{article}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsthm}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}

\newtheorem{theorem}{Theorem}
\newtheorem{prop}{Proposition}

\begin{document}

\title{Optimization Hw4}
\author{Toby Harvey}
\maketitle
\noindent\textbf{Problem 1}

\noindent Showing that the linear program is a relaxation of the integer program:

First we need that every feasible solution to the integer program is a feasible solution to the linear program. A feasible solution to the integer program consists of any 0,1 vector x with exactly $k$ 1's. In the linear program we let $0 \leq x_i \leq 1$, and still maintain that the sum of terms in $x$ is $k$. Since we can have a feasible 0,1 vector of $k$ 1's in the linear program, the feasible solutions of the integer program are a subset of the feasible solutions to the linear program.

Second we need that the objective function values of feasiable solutions in the integer program are the same as the objective function values in linear program. Let $y_{ij} = x_i + x_j - 2x_ix_j$, and since $z_{ij}$ takes its upper bound from which ever constraint $z_{ij} \leq x_i + x_j$ or $z_{ij} \leq 2 - x_i - x_j$ forces a lower value we really have $z_{ij} \leq \min\{x_i+ x_j, 2 - x_i - x_j \}$, and since we are maximizing there is no reason $z_{ij}$ will not be in equality so we have, $z_{ij} = \min\{x_i + x_j, 2 - x_i - x_j\}$. Observing the the 4 possible values of $y_{ij}$ in the integer program, we see that with both $x_i$, and $x_j$ equal to 1, $y_{ij}$ will be 0. With a single decision variable equal to 1, $y_{ij}$ equals 1. And with both 0, $y_{ij}$ wil be 0. So we $w_{ij}$ for each term only if a single vertex is choosen between the edge $(i,j)$. Going through the same cases for $z_{ij}$ we get the exact same values as $y_{ij}$ in each case. Meaning we gain $w_{ij}$ in the same circumstances in the linear program with integer valued solution, as we did in the integer program.

\vspace{5mm}

\noindent Showing that $\sum_{(i,j) \in \mathcal{E}} w_{ij}(x_i + x_j - 2x_ix_j) \geq \frac{1}{2} \sum_{(i,j) \in \mathcal{E}} w_{ij}z_{ij}$ : 

\vspace{3mm}

Since we are just scaling $w_{ij}$ and summing over edges in both cases, it suffices to show:

$$(x_i + x_j - 2x_ix_j) \geq \frac{1}{2} z_{ij} \qquad \forall (i,j) \in \mathcal{E}$$

Replacing $z_{ij}$ with the expression we found before we have that we need:

$$(x_i + x_j - 2x_ix_j) \geq \frac{1}{2}  \min\{x_i + x_j, 2 - (x_i + x_j)\} \qquad \forall (i,j) \in \mathcal{E}$$

Looking at the RHS, we can split this inequality into two cases. One when $x_i + x_j \leq 1$, and we have the first term in the minimization, and the other when $x_i + x_j \geq 1$ and we have the second term in the minimization.

\vspace{3mm}

\noindent Showing $x_i + x_j - 2x_ix_j \geq \frac{1}{2} (x_i + x_j)$ or (rearraging) $x_i + x_j \geq 4x_ix_j$  when $0 \leq x_i + x_j \leq 1$, $0 \leq x_i \leq 1$, and  $0 \leq x_j \leq 1$:

\vspace{3mm}

We have:

$$x_i + x_j \geq (x_i + x_j)^2 \geq 4x_ix_j$$

\vspace{3mm}

\noindent Showing  $x_i + x_j - 2x_ix_j \geq \frac{1}{2} (2 - x_i - x_j)$ or (rearraging) $3(x_i + x_j) - 4x_ix_j - 2 \geq 0$ when $1 \leq x_i + x_j \leq 2$, $0 \leq x_i \leq 1$, and  $0 \leq x_j \leq 1$:

\vspace{3mm}

\noindent Taking the gradient of the LHS we get and setting it equal to zero we get:

\begin{gather*}
  3 - 4x_j = 0 \implies x_j = \frac{3}{4}\\
  3 - 4x_i = 0 \implies x_i = \frac{3}{4}\\
\end{gather*}

We therefore have a critical point with value $\frac{1}{4}$. Since the second derivative is negative we see we have a maximum at this point. Checking the end points of $1 \leq x_i + x_j \leq 2$ to see if they are positive will therefore tell us if this expression is greater than 0 in the intervals we care about. In the $x_i + x_j = 1$ case we get at very most (when $x_i = \frac{1}{2}$ and $x_j = \frac{1}{2}$...argument again by differentation on the second term if we need):
$$3 - 1 -2 \geq 0$$

Which is true, in the $x_i + x_j = 2$ cause we get at very most:

$$6 - 4 - 2 \geq 0$$

Which is also true. So we have the result.

\vspace{3mm}

\noindent Showing that pipage rounding does not decrease $F(x)$:

\vspace{3mm}

\noindent First note that by the second property of pipage rounding discussed in class, we maintain feasability when we pipage round. 
Secondly observe that from the constraints in the linear program $0 \leq z_{ij} \leq 1$ therefore when we pipage round with either ``path'' we push the pair of decsion variable in opposite directions one to 0 and the other to 1. Iteratively doing this for all non integer decision variables results in $x_i$ or $x_j$ being 1 and the other being 0, which also results in the maximum integer value of $x_i + x_j - 2x_ix_j$. Therefore $F(x)$ will not decrease.

The resulting algorithim is then: Solve the linear relaxation, and then pick a pair on non integer valued decision variables, let $w = \min \{x_i, 1-x_j \}$, add $w$ to $x_i$, subtract $w$ from $x_j$. Repeat until we have a integer solution.

\newpage

\noindent\textbf{Problem 2}

Splitting the nodes into two set with even $\frac{1}{2}$ probability of being in either set, gives a $\frac{1}{4}$ approximation. To show this let $x_{ij}$ be a random variable such that if the edge $(i,j)$ is going from $\mathcal{V}$ to $\mathcal{U}$ then $x_{ij}$ is 1, and 0 otherwise. Then if $Z$ is the random variable of total weights over the partition. Then:

\begin{gather*}
  E[Z] = \sum_{(i,j)\in \mathcal{E}}w_{ij}E[x_{ij}] =  \sum_{(i,j)\in \mathcal{E}}w_{ij} (1 \cdot Pr(i \in \mathcal{V} \text{ and } j \in \mathcal{U}) + 0 \cdot Pr(\text{not}))\\
  E[Z] = \sum_{(i,j)\in \mathcal{E}}w_{ij}(1 \cdot \frac{1}{2} \cdot \frac{1}{2}) = \frac{1}{4} \sum_{(i,j)\in \mathcal{E}}w_{ij} \geq \frac{1}{4}\text{OPT}\\
\end{gather*}
Where the last inequality is from the total weight being an upper bound on OPT.


\vspace{3mm}

\noindent Showing that the linear program is a relaxation of the problem:

\vspace{3mm}

Assuming $x_i$ is a decision variable such that if $x_i = 1$ then $i \in \mathcal{V}$, and if $x_i= 0$ $i \in \mathcal{U}$. Similar two the other problem, we can see that the two constraints on $z_{ij}$ can be written as $z_{ij} = \max \{x_i, 1-x_j\}$. If we take $x_i$ to be only 0,1, then $w_{ij}$ is only taken when $i \in \mathcal{V}$, and $j \in \mathcal{U}$ which models the problem exactly. Relaxing $x_i$ and $z_{ij}$ to inbetween 0 and 1, we still maintain all feasiable points from the integer version, and the objective function still gives the same values for 0,1 instances.

\vspace{3mm}


\noindent Showing that if we put $i \in \mathcal{V}$ with probability $\frac{1}{2}x_i + \frac{1}{4}$, we get a $\frac{1}{2}$ approximation:

\vspace{3mm}

First we need to related $z_{ij}$ to the probability that $i \in \mathcal{V}$ and  $j \in \mathcal{U}$ given an edge, so that we can later use it in expetation calculation:

\begin{gather*}
  \text{Pr}(i \in \mathcal{V} \text{ and }  j \in \mathcal{U})\\
  = \text{Pr}(i \in \mathcal{V})\text{Pr}(j \in \mathcal{U})\\
  = \left(\frac{1}{2}x_i + \frac{1}{4}\right)\left(1 - \frac{1}{2}x_j - \frac{1}{4}\right)\\
  = \left(\frac{1}{2}x_i + \frac{1}{4}\right)\left(\frac{1}{4} + \left(\frac{1}{2} - \frac{1}{2}x_j\right)\right)\\
  \geq \left(\frac{1}{2}z_{ij} + \frac{1}{4}\right)\left(\frac{1}{4} + \frac{1}{2}z_{ij}\right)\\
  = \frac{1}{4}z_{ij}^2 + \frac{1}{4}z_{ij} + \frac{1}{16} - \frac{1}{2}z_{ij} + \frac{1}{2}z_{ij}\\
  \geq  \frac{1}{2}z_{ij}
\end{gather*}

Where the last inequality is by the fact that the first 4 terms in the expression achieve a minimum of 0 when $z_{ij} = \frac{1}{2}$ (i.e. $\frac{d}{dz_{ij}}(\frac{1}{4}z_{ij}^2 + \frac{1}{4}z_{ij} + \frac{1}{16} - \frac{1}{2}z_{ij}) = 0 \implies z_{ij} = \frac{1}{2}$, and  $\frac{d^2}{d^2z_{ij}} > 0$) , so in all other cases, the first 4 terms together are greater than 0. Knowing this we can take the expected value of the total weight obtained:

\begin{gather*}
  E[\mathcal{U}] = \sum_{(i,j)}E[x_{ij}]w_{ij} = \sum_{(i,j)} \text{Pr}(i \in \mathcal{V} \text{ and }  j \in \mathcal{U})w_{ij}\\
  \geq \sum_{(i,j)}\frac{z_{ij}}{2}w_{ij} = \frac{1}{2}\sum_{(i,j)}z_{ij}w_{ij} \geq \frac{1}{2} \text{OPT}
\end{gather*}

\noindent And we have a $\frac{1}{2}$ appromixation.



\end{document}
